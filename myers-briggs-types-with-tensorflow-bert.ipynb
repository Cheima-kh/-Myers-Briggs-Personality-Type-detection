{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/mbti-type/mbti_1.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/mbti-type/mbti_1.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   type                                              posts\n0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n1  ENTP  'I'm finding the lack of me in these posts ver...\n2  INTP  'Good one  _____   https://www.youtube.com/wat...\n3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n4  ENTJ  'You're fired.|||That's another silly misconce...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The first thing I want to do is turn the personality types into numbered categories, ranging from 0 to 15. These will serve as the output of the model when it is categorizing people."},{"metadata":{"trusted":true},"cell_type":"code","source":"types = np.unique(data.type.values)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_type_index(string):\n    return list(types).index(string)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['type_index'] = data['type'].apply(get_type_index)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.posts.values[0]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"\"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\""},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now, I want to clean the text to get rid of hyperlinks, puncuation, and anything else that's cluttering up the text. Specifically, the pipe (|) character seems like it separates different posts, but without spaces between them. First, I'm going to replace the pipes with spaces so that the tokenizer won't parse those parts as one long word. Then, I'll clean up the rest."},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport re\n\ndef clean_text(text):\n    regex = re.compile('[%s]' % re.escape('|'))\n    text = regex.sub(\" \", text)\n    words = str(text).split()\n    words = [i.lower() + \" \" for i in words]\n    words = [i for i in words if not \"http\" in i]\n    words = \" \".join(words)\n    words = words.translate(words.maketrans('', '', string.punctuation))\n    return words\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cleaned_text'] = data['posts'].apply(clean_text)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.cleaned_text.values[0]","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"'enfp  and  intj  moments  sportscenter  not  top  ten  plays  pranks  what  has  been  the  most  lifechanging  experience  in  your  life  on  repeat  for  most  of  today  may  the  perc  experience  immerse  you  the  last  thing  my  infj  friend  posted  on  his  facebook  before  committing  suicide  the  next  day  rest  in  peace  hello  enfj7  sorry  to  hear  of  your  distress  its  only  natural  for  a  relationship  to  not  be  perfection  all  the  time  in  every  moment  of  existence  try  to  figure  the  hard  times  as  times  of  growth  as  84389  84390    welcome  and  stuff  game  set  match  prozac  wellbrutin  at  least  thirty  minutes  of  moving  your  legs  and  i  dont  mean  moving  them  while  sitting  in  your  same  desk  chair  weed  in  moderation  maybe  try  edibles  as  a  healthier  alternative  basically  come  up  with  three  items  youve  determined  that  each  type  or  whichever  types  you  want  to  do  would  more  than  likely  use  given  each  types  cognitive  functions  and  whatnot  when  left  by  all  things  in  moderation  sims  is  indeed  a  video  game  and  a  good  one  at  that  note  a  good  one  at  that  is  somewhat  subjective  in  that  i  am  not  completely  promoting  the  death  of  any  given  sim  dear  enfp  what  were  your  favorite  video  games  growing  up  and  what  are  your  now  current  favorite  video  games  cool  it  appears  to  be  too  late  sad  theres  someone  out  there  for  everyone  wait  i  thought  confidence  was  a  good  thing  i  just  cherish  the  time  of  solitude  bc  i  revel  within  my  inner  world  more  whereas  most  other  time  id  be  workin  just  enjoy  the  me  time  while  you  can  dont  worry  people  will  always  be  around  to  yo  entp  ladies  if  youre  into  a  complimentary  personalitywell  hey    when  your  main  social  outlet  is  xbox  live  conversations  and  even  then  you  verbally  fatigue  quickly  i  really  dig  the  part  from  146  to  250  banned  because  this  thread  requires  it  of  me  get  high  in  backyard  roast  and  eat  marshmellows  in  backyard  while  conversing  over  something  intellectual  followed  by  massages  and  kisses  banned  for  too  many  bs  in  that  sentence  how  could  you  think  of  the  b  banned  for  watching  movies  in  the  corner  with  the  dunces  banned  because  health  class  clearly  taught  you  nothing  about  peer  pressure  banned  for  a  whole  host  of  reasons  1  two  baby  deer  on  left  and  right  munching  on  a  beetle  in  the  middle  2  using  their  own  blood  two  cavemen  diary  todays  latest  happenings  on  their  designated  cave  diary  wall  3  i  see  it  as  a  pokemon  world  an  infj  society  everyone  becomes  an  optimist  49142  not  all  artists  are  artists  because  they  draw  its  the  idea  that  counts  in  forming  something  of  your  own  like  a  signature  welcome  to  the  robot  ranks  person  who  downed  my  selfesteem  cuz  im  not  an  avid  signature  artist  like  herself  proud  banned  for  taking  all  the  room  under  my  bed  ya  gotta  learn  to  share  with  the  roaches  banned  for  being  too  much  of  a  thundering  grumbling  kind  of  storm  yep  ahh  old  high  school  music  i  havent  heard  in  ages  i  failed  a  public  speaking  class  a  few  years  ago  and  ive  sort  of  learned  what  i  could  do  better  were  i  to  be  in  that  position  again  a  big  part  of  my  failure  was  just  overloading  myself  with  too  i  like  this  persons  mentality  hes  a  confirmed  intj  by  the  way  move  to  the  denver  area  and  start  a  new  life  for  myself '"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"   type                                              posts  type_index  \\\n0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           8   \n1  ENTP  'I'm finding the lack of me in these posts ver...           3   \n2  INTP  'Good one  _____   https://www.youtube.com/wat...          11   \n3  INTJ  'Dear INTP,   I enjoyed our conversation the o...          10   \n4  ENTJ  'You're fired.|||That's another silly misconce...           2   \n\n                                        cleaned_text  \n0  enfp  and  intj  moments  sportscenter  not  t...  \n1  im  finding  the  lack  of  me  in  these  pos...  \n2  good  one    of  course  to  which  i  say  i ...  \n3  dear  intp  i  enjoyed  our  conversation  the...  \n4  youre  fired  thats  another  silly  misconcep...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n      <th>type_index</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n      <td>8</td>\n      <td>enfp  and  intj  moments  sportscenter  not  t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n      <td>3</td>\n      <td>im  finding  the  lack  of  me  in  these  pos...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n      <td>11</td>\n      <td>good  one    of  course  to  which  i  say  i ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n      <td>10</td>\n      <td>dear  intp  i  enjoyed  our  conversation  the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n      <td>2</td>\n      <td>youre  fired  thats  another  silly  misconcep...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now, we split the data into training, testing, and validation sets,"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data)\ntrain, val = train_test_split(train)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Keras has a great tokenizer that we can use to turn sequences of words into arrays of numbers. For more information, see: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nvocab_size = 10000\ntrunc_type = \"post\"\npad_type = \"post\"\noov_tok = \"<OOV>\"\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(data.cleaned_text.values)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 1500\ntrain_sequences = tokenizer.texts_to_sequences(train.cleaned_text.values)\ntrain_padded = pad_sequences(train_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)\n\nval_sequences = tokenizer.texts_to_sequences(val.cleaned_text.values)\nval_padded = pad_sequences(val_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_padded","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"array([[  48, 3702, 7640, ...,    0,    0,    0],\n       [   3,  192,    9, ...,    0,    0,    0],\n       [  62,  233,  576, ...,    0,    0,    0],\n       ...,\n       [ 560, 7318,  149, ...,    0,    0,    0],\n       [   2,  157,   45, ...,    0,    0,    0],\n       [ 783,  605,    3, ...,   45,  103,    9]], dtype=int32)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So, our model is going to take in these arrays of numbers that represent the text, and it's going to output the personality type that it thinks is associated with it. Here, I'm going to convert the personality types to one-hot-encoded labels. This simply means that to represent a particular category, we make an array with the length of the total possible number of categories, and make all of the values zero except at the index of the category we're trying to represent. "},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_labels = tf.keras.utils.to_categorical(train.type_index.values, num_classes=16)\nval_labels= tf.keras.utils.to_categorical(val.type_index.values, num_classes=16)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n\ndef create_model():\n    op = tf.keras.optimizers.Adam(learning_rate=0.00001)\n\n    model = Sequential()\n    model.add(Embedding(vocab_size, 256, input_length=maxlen-1))\n    model.add(Dropout(0.3))\n    model.add(Bidirectional(LSTM(200, return_sequences=True)))\n    model.add(Dropout(0.3))\n    model.add(Bidirectional(LSTM(20)))\n    model.add(Dropout(0.3))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(16, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n    return model","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using a TPU can greatly reduce the amount of time spent training the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"use_tpu = True\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        model = create_model()\nelse:\n    model = create_model()\n    \nmodel.summary()","execution_count":19,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1499, 256)         2560000   \n_________________________________________________________________\ndropout (Dropout)            (None, 1499, 256)         0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 1499, 400)         731200    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1499, 400)         0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 40)                67360     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 40)                0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                2624      \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                1040      \n=================================================================\nTotal params: 3,362,224\nTrainable params: 3,362,224\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_padded, one_hot_labels, epochs =20, verbose = 1, \n          validation_data = (val_padded, val_labels),  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3)])","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n153/153 [==============================] - 34s 225ms/step - loss: 2.7681 - accuracy: 0.0953 - val_loss: 2.7551 - val_accuracy: 0.2090\nEpoch 2/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.7379 - accuracy: 0.1970 - val_loss: 2.7033 - val_accuracy: 0.2151\nEpoch 3/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.6606 - accuracy: 0.2033 - val_loss: 2.5631 - val_accuracy: 0.2151\nEpoch 4/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.5707 - accuracy: 0.1941 - val_loss: 2.5129 - val_accuracy: 0.2151\nEpoch 5/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.5328 - accuracy: 0.1882 - val_loss: 2.4780 - val_accuracy: 0.2151\nEpoch 6/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.4800 - accuracy: 0.2068 - val_loss: 2.4115 - val_accuracy: 0.2151\nEpoch 7/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.4373 - accuracy: 0.2029 - val_loss: 2.3690 - val_accuracy: 0.2151\nEpoch 8/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.4070 - accuracy: 0.2039 - val_loss: 2.3449 - val_accuracy: 0.2151\nEpoch 9/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3935 - accuracy: 0.2050 - val_loss: 2.3294 - val_accuracy: 0.2151\nEpoch 10/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3749 - accuracy: 0.2015 - val_loss: 2.3173 - val_accuracy: 0.2151\nEpoch 11/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3740 - accuracy: 0.1986 - val_loss: 2.3081 - val_accuracy: 0.2151\nEpoch 12/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3640 - accuracy: 0.1974 - val_loss: 2.3014 - val_accuracy: 0.2151\nEpoch 13/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3543 - accuracy: 0.1990 - val_loss: 2.2954 - val_accuracy: 0.2151\nEpoch 14/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3458 - accuracy: 0.2002 - val_loss: 2.2903 - val_accuracy: 0.2151\nEpoch 15/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3532 - accuracy: 0.1968 - val_loss: 2.2875 - val_accuracy: 0.2151\nEpoch 16/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3408 - accuracy: 0.2017 - val_loss: 2.2839 - val_accuracy: 0.2151\nEpoch 17/20\n153/153 [==============================] - 30s 194ms/step - loss: 2.3384 - accuracy: 0.1988 - val_loss: 2.2808 - val_accuracy: 0.2151\nEpoch 18/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3410 - accuracy: 0.1892 - val_loss: 2.2785 - val_accuracy: 0.2151\nEpoch 19/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3328 - accuracy: 0.2013 - val_loss: 2.2762 - val_accuracy: 0.2151\nEpoch 20/20\n153/153 [==============================] - 30s 193ms/step - loss: 2.3374 - accuracy: 0.1974 - val_loss: 2.2747 - val_accuracy: 0.2151\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f87b7ab10d0>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"This model didn't do very well, only achieving around 20% accuracy. This is a difficult challenge- to classify people into 16 different categories based on text that may loosely correlate with those categories. Let's see if we can do a bit better by incorporating a transformer. I used the one from this Keras example: https://keras.io/examples/nlp/text_classification_with_transformer/\n\nFor more information about transformers in general, see: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow import keras\nclass MultiHeadSelfAttention(layers.Layer):\n    def __init__(self, embed_dim, num_heads=8):\n        super(MultiHeadSelfAttention, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        if embed_dim % num_heads != 0:\n            raise ValueError(\n                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n            )\n        self.projection_dim = embed_dim // num_heads\n        self.query_dense = layers.Dense(embed_dim)\n        self.key_dense = layers.Dense(embed_dim)\n        self.value_dense = layers.Dense(embed_dim)\n        self.combine_heads = layers.Dense(embed_dim)\n\n    def attention(self, query, key, value):\n        score = tf.matmul(query, key, transpose_b=True)\n        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n        scaled_score = score / tf.math.sqrt(dim_key)\n        weights = tf.nn.softmax(scaled_score, axis=-1)\n        output = tf.matmul(weights, value)\n        return output, weights\n\n    def separate_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n\n    def call(self, inputs):\n        # x.shape = [batch_size, seq_len, embedding_dim]\n        batch_size = tf.shape(inputs)[0]\n        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n        query = self.separate_heads(\n            query, batch_size\n        )  # (batch_size, num_heads, seq_len, projection_dim)\n        key = self.separate_heads(\n            key, batch_size\n        )  # (batch_size, num_heads, seq_len, projection_dim)\n        value = self.separate_heads(\n            value, batch_size\n        )  # (batch_size, num_heads, seq_len, projection_dim)\n        attention, weights = self.attention(query, key, value)\n        attention = tf.transpose(\n            attention, perm=[0, 2, 1, 3]\n        )  # (batch_size, seq_len, num_heads, projection_dim)\n        concat_attention = tf.reshape(\n            attention, (batch_size, -1, self.embed_dim)\n        )  # (batch_size, seq_len, embed_dim)\n        output = self.combine_heads(\n            concat_attention\n        )  # (batch_size, seq_len, embed_dim)\n        return output","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TokenAndPositionEmbedding(layers.Layer):\n    def __init__(self, maxlen, vocab_size, emded_dim):\n        super(TokenAndPositionEmbedding, self).__init__()\n        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=emded_dim)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        x = self.token_emb(x)\n        return x + positions\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_dim = 32  # Embedding size for each token\nnum_heads = 2  # Number of attention heads\nff_dim = 32  # Hidden layer size in feed forward network inside transformer\n\ndef create_model(): \n    inputs = layers.Input(shape=(maxlen,))\n    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n    x = embedding_layer(inputs)\n    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n    x = transformer_block(x)\n    # x = layers.GlobalAveragePooling1D()(x)\n    # x = layers.Dropout(0.1)(x)\n    x = (Bidirectional(LSTM(200, return_sequences=True)))(x)\n    x = (Dropout(0.3))(x)\n    x = (Bidirectional(LSTM(20)))(x)\n    x = layers.Dense(20, activation=\"relu\")(x)\n    x = layers.Dropout(0.1)(x)\n    outputs = layers.Dense(16, activation=\"softmax\")(x)\n    \n    op = tf.keras.optimizers.Adam(learning_rate=0.00001)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    model.compile(op, 'categorical_crossentropy', metrics = ['accuracy'])\n    return model","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_tpu = True\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        model = create_model()\nelse:\n    model = create_model()\n    \nmodel.summary()","execution_count":25,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 1500)]            0         \n_________________________________________________________________\ntoken_and_position_embedding (None, 1500, 32)          368000    \n_________________________________________________________________\ntransformer_block (Transform (None, 1500, 32)          6464      \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 1500, 400)         372800    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 1500, 400)         0         \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, 40)                67360     \n_________________________________________________________________\ndense_8 (Dense)              (None, 20)                820       \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 20)                0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 16)                336       \n=================================================================\nTotal params: 815,780\nTrainable params: 815,780\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_padded, one_hot_labels, epochs =30, verbose = 1, \n          validation_data = (val_padded, val_labels), callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3)])","execution_count":26,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n153/153 [==============================] - 32s 212ms/step - loss: 2.7164 - accuracy: 0.0611 - val_loss: 2.6803 - val_accuracy: 0.1057\nEpoch 2/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.6551 - accuracy: 0.1804 - val_loss: 2.6016 - val_accuracy: 0.2004\nEpoch 3/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.5917 - accuracy: 0.1972 - val_loss: 2.5489 - val_accuracy: 0.2163\nEpoch 4/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.5554 - accuracy: 0.1941 - val_loss: 2.5129 - val_accuracy: 0.2151\nEpoch 5/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.5305 - accuracy: 0.1984 - val_loss: 2.4887 - val_accuracy: 0.2151\nEpoch 6/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.5155 - accuracy: 0.1923 - val_loss: 2.4711 - val_accuracy: 0.2151\nEpoch 7/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.5013 - accuracy: 0.1986 - val_loss: 2.4582 - val_accuracy: 0.2151\nEpoch 8/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.4909 - accuracy: 0.1978 - val_loss: 2.4473 - val_accuracy: 0.2151\nEpoch 9/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4796 - accuracy: 0.2025 - val_loss: 2.4375 - val_accuracy: 0.2151\nEpoch 10/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4777 - accuracy: 0.1947 - val_loss: 2.4290 - val_accuracy: 0.2151\nEpoch 11/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4669 - accuracy: 0.1976 - val_loss: 2.4211 - val_accuracy: 0.2151\nEpoch 12/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4550 - accuracy: 0.2078 - val_loss: 2.4131 - val_accuracy: 0.2151\nEpoch 13/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4519 - accuracy: 0.2000 - val_loss: 2.4063 - val_accuracy: 0.2151\nEpoch 14/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4462 - accuracy: 0.2002 - val_loss: 2.4004 - val_accuracy: 0.2151\nEpoch 15/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4384 - accuracy: 0.2007 - val_loss: 2.3936 - val_accuracy: 0.2151\nEpoch 16/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4348 - accuracy: 0.1904 - val_loss: 2.3878 - val_accuracy: 0.2151\nEpoch 17/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4340 - accuracy: 0.1972 - val_loss: 2.3830 - val_accuracy: 0.2151\nEpoch 18/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.4179 - accuracy: 0.2029 - val_loss: 2.3779 - val_accuracy: 0.2151\nEpoch 19/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4215 - accuracy: 0.1949 - val_loss: 2.3738 - val_accuracy: 0.2157\nEpoch 20/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4179 - accuracy: 0.1974 - val_loss: 2.3692 - val_accuracy: 0.2157\nEpoch 21/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4118 - accuracy: 0.1986 - val_loss: 2.3647 - val_accuracy: 0.2157\nEpoch 22/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4092 - accuracy: 0.2015 - val_loss: 2.3608 - val_accuracy: 0.2163\nEpoch 23/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.4071 - accuracy: 0.1949 - val_loss: 2.3575 - val_accuracy: 0.2120\nEpoch 24/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.4029 - accuracy: 0.1964 - val_loss: 2.3535 - val_accuracy: 0.2163\nEpoch 25/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.3919 - accuracy: 0.2019 - val_loss: 2.3500 - val_accuracy: 0.2151\nEpoch 26/30\n153/153 [==============================] - 26s 168ms/step - loss: 2.3897 - accuracy: 0.2031 - val_loss: 2.3462 - val_accuracy: 0.2170\nEpoch 27/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.3815 - accuracy: 0.2095 - val_loss: 2.3433 - val_accuracy: 0.2145\nEpoch 28/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.3795 - accuracy: 0.2021 - val_loss: 2.3406 - val_accuracy: 0.2016\nEpoch 29/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.3737 - accuracy: 0.2107 - val_loss: 2.3353 - val_accuracy: 0.2139\nEpoch 30/30\n153/153 [==============================] - 26s 169ms/step - loss: 2.3622 - accuracy: 0.2107 - val_loss: 2.3322 - val_accuracy: 0.2120\n","name":"stdout"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f8764195fd0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import transformers\ntokenizer = transformers.AutoTokenizer.from_pretrained('bert-large-uncased')","execution_count":27,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f30d8ca225194211a8e1793d13f14bcf"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bc70ccc0ef947c5a24e446387b51cfc"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 1500\n\ntrain_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in train.cleaned_text.values]\nval_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in val.cleaned_text.values]","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(): \n    input_word_ids = tf.keras.layers.Input(shape=(maxlen,), dtype=tf.int32,\n                                           name=\"input_word_ids\")\n    bert_layer = transformers.TFBertModel.from_pretrained('bert-large-uncased')\n    bert_outputs = bert_layer(input_word_ids)[0]\n    pred = tf.keras.layers.Dense(16, activation='softmax')(bert_outputs[:,0,:])\n    \n    model = tf.keras.models.Model(inputs=input_word_ids, outputs=pred)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n    learning_rate=0.00001), metrics=['accuracy'])\n    return model","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_tpu = True\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        model = create_model()\nelse:\n    model = create_model()\n    \nmodel.summary()","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1472569832.0, style=ProgressStyle(descr…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9589d91566484e8c9efb3befeeab8e"}},"metadata":{}},{"output_type":"stream","text":"\nModel: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_word_ids (InputLayer)  [(None, 1500)]            0         \n_________________________________________________________________\ntf_bert_model (TFBertModel)  ((None, 1500, 1024), (Non 335141888 \n_________________________________________________________________\ntf_op_layer_strided_slice (T [(None, 1024)]            0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 16)                16400     \n=================================================================\nTotal params: 335,158,288\nTrainable params: 335,158,288\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\n\nmodel.fit(np.array(train_input_ids), one_hot_labels,validation_data = (np.array(val_input_ids), val_labels),\n          verbose = 1, epochs = 20, batch_size = batch_size,  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5)])","execution_count":31,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n305/305 [==============================] - 252s 827ms/step - loss: 2.2753 - accuracy: 0.2466 - val_loss: 1.9208 - val_accuracy: 0.4173\nEpoch 2/20\n305/305 [==============================] - 227s 746ms/step - loss: 1.6576 - accuracy: 0.5071 - val_loss: 1.4305 - val_accuracy: 0.5753\nEpoch 3/20\n305/305 [==============================] - 227s 745ms/step - loss: 1.3358 - accuracy: 0.6055 - val_loss: 1.2246 - val_accuracy: 0.6269\nEpoch 4/20\n305/305 [==============================] - 227s 745ms/step - loss: 1.1692 - accuracy: 0.6415 - val_loss: 1.1644 - val_accuracy: 0.6423\nEpoch 5/20\n305/305 [==============================] - 227s 745ms/step - loss: 1.0331 - accuracy: 0.6907 - val_loss: 1.2339 - val_accuracy: 0.6318\nEpoch 6/20\n305/305 [==============================] - 227s 745ms/step - loss: 0.9202 - accuracy: 0.7163 - val_loss: 1.1801 - val_accuracy: 0.6454\nEpoch 7/20\n305/305 [==============================] - 227s 745ms/step - loss: 0.7643 - accuracy: 0.7674 - val_loss: 1.3042 - val_accuracy: 0.6343\nEpoch 8/20\n305/305 [==============================] - 227s 746ms/step - loss: 0.6467 - accuracy: 0.8018 - val_loss: 1.2607 - val_accuracy: 0.6515\nEpoch 9/20\n305/305 [==============================] - 227s 746ms/step - loss: 0.4507 - accuracy: 0.8584 - val_loss: 1.3793 - val_accuracy: 0.6349\n","name":"stdout"},{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f8764125090>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in test.cleaned_text.values]\ntest_labels= tf.keras.utils.to_categorical(test.type_index.values, num_classes=16)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(np.array(test_input_ids), test_labels)","execution_count":33,"outputs":[{"output_type":"stream","text":"68/68 [==============================] - 20s 292ms/step - loss: 1.3413 - accuracy: 0.6487\n","name":"stdout"},{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"[1.3412909507751465, 0.6486860513687134]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}